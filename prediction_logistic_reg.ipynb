{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from models import *\n",
    "from helpers import *\n",
    "from build import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[ 1. -1. -1.  1.  1.  1. -1. -1.  1. -1.]\n",
      "[[  1.38470000e+02   5.16550000e+01   9.78270000e+01   2.79800000e+01\n",
      "    9.10000000e-01   1.24711000e+02   2.66600000e+00   3.06400000e+00\n",
      "    4.19280000e+01   1.97760000e+02   1.58200000e+00   1.39600000e+00\n",
      "    2.00000000e-01   3.26380000e+01   1.01700000e+00   3.81000000e-01\n",
      "    5.16260000e+01   2.27300000e+00  -2.41400000e+00   1.68240000e+01\n",
      "   -2.77000000e-01   2.58733000e+02   2.00000000e+00   6.74350000e+01\n",
      "    2.15000000e+00   4.44000000e-01   4.60620000e+01   1.24000000e+00\n",
      "   -2.47500000e+00   1.13497000e+02]\n",
      " [  2.19057000e+02   7.24610000e+01   1.24835000e+02   5.50600000e+00\n",
      "   -9.99000000e+02  -9.99000000e+02  -9.99000000e+02   3.77100000e+00\n",
      "    4.69360000e+01   1.22986000e+02   1.93200000e+00  -1.38200000e+00\n",
      "   -9.99000000e+02   2.47590000e+01  -1.06300000e+00   3.32000000e-01\n",
      "    4.78300000e+01   1.34700000e+00  -2.56900000e+00   2.84990000e+01\n",
      "    9.60000000e-01   9.03550000e+01   1.00000000e+00   5.03960000e+01\n",
      "   -7.08000000e-01  -6.42000000e-01  -9.99000000e+02  -9.99000000e+02\n",
      "   -9.99000000e+02   5.03960000e+01]]\n",
      "[100000 100050 100100 100150 100200 100250 100300 100350 100400 100450]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "head = range(10)\n",
    "print(y[head])\n",
    "print(tX[ range(2) ])\n",
    "print(ids[head])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a simple linear regression with least_square gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.56608363e+59,   1.10782626e+59,   1.62451845e+59,\n",
       "         6.26336910e+58,  -2.01610081e+60,  -2.04793050e+60,\n",
       "        -2.01579484e+60,   5.04332859e+57,   2.88293272e+58,\n",
       "         1.96937732e+59,   2.82441729e+57,  -1.06706918e+57,\n",
       "        -2.01597045e+60,   6.86296372e+58,   1.18364804e+55,\n",
       "         7.30831677e+54,   8.65034239e+58,  -5.15820142e+55,\n",
       "         2.15281385e+56,   7.01699928e+58,  -2.88226035e+54,\n",
       "         2.97018336e+59,   6.70599200e+56,  -1.20485188e+60,\n",
       "        -1.25039788e+60,  -1.25035089e+60,  -2.01883416e+60,\n",
       "        -2.01594418e+60,  -2.01593459e+60,   4.18046866e+58])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1.0\n",
    "max_iter = 10\n",
    "loss, w = least_squares_SGD(y, tX, gamma, max_iter)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=[[ 3465.7359028]]\n",
      "Calculation failed! [ 3003.90589018]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7adb71e7ef0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/models.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, gamma, max_iters)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_reg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;31m# log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/models.py\u001b[0m in \u001b[0;36mone_step_reg_logistic_regression\u001b[0;34m(y, tx, w, lambda_, gamma)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_hessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/costs.py\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(y, tx, w, method)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# return calculate_rmse(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_negative_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/costs.py\u001b[0m in \u001b[0;36mcalculate_negative_log_likelihood\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOverflowError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculation failed!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "loss, w = reg_logistic_regression(y, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 1.0\n",
    "max_iter = 10\n",
    "loss, w = least_squares_SGD(y, tX, gamma, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tX[ range(3)])\n",
    "x_first_column = tX[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's do a prediction only about first column, just for fun\n",
    "tx_first_column = build_poly(x_first_column, 2)\n",
    "loss, w = least_squares_SGD(y, tX, gamma, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(w))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tX.shape)\n",
    "np.var(tX, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some cross-validation, same as the HW4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from build_polynomial import build_poly\n",
    "\n",
    "def cross_validation(y, tX, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    ytest = y[k_indices[k]]\n",
    "    tXtest = tX[k_indices[k]]\n",
    "    \n",
    "    not_k = np.array([i for i in range(len(y)) if i not in k_indices[k]])\n",
    "    ytrain = y[not_k]\n",
    "    tXtrain = tX[not_k]\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    _, w = ridge_regression(ytrain, tXtrain, lambda_)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate the loss for train and test data: TODO\n",
    "    # ***************************************************\n",
    "    loss_tr = compute_loss(ytrain, tXtrain, w)\n",
    "    loss_te = compute_loss(ytest, tXtest, w)\n",
    "    \n",
    "\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import cross_validation_visualization\n",
    "from build_k_indices import *\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 1\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-10, 2, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # *************************************************** \n",
    "    for lambda_ in lambdas:\n",
    "        trainerrors = []\n",
    "        testerrors = []\n",
    "        for k in range(k_fold):\n",
    "            trainerror, testerror = cross_validation(y, tX, k_indices, k, lambda_)\n",
    "            trainerrors.append(trainerror)\n",
    "            testerrors.append(testerror)\n",
    "        \n",
    "        mse_tr.append(np.mean(trainerrors))\n",
    "        mse_te.append(np.mean(testerrors))\n",
    "    \n",
    "    \n",
    "    cross_validation_visualization(lambdas, mse_tr, mse_te)\n",
    "\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we choose a lambda near z√©ro (then just a least_square_GD), we will test our stupid regression with least_square_GD and variation of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from build_polynomial import build_poly\n",
    "from plots import cross_validation_visualization\n",
    "from build_k_indices import *\n",
    "\n",
    "def cross_validation(y, tX, k_indices, k, gamma):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    ytest = y[k_indices[k]]\n",
    "    tXtest = tX[k_indices[k]]\n",
    "    \n",
    "    not_k = np.array([i for i in range(len(y)) if i not in k_indices[k]])\n",
    "    ytrain = y[not_k]\n",
    "    tXtrain = tX[not_k]\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    max_iters = 10\n",
    "    loss, w = least_squares_GD(ytrain, tXtrain, gamma, max_iters)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate the loss for train and test data: TODO\n",
    "    # ***************************************************\n",
    "    loss_tr = compute_loss(ytrain, tXtrain, w)\n",
    "    loss_te = compute_loss(ytest, tXtest, w)\n",
    "\n",
    "    return loss_tr, loss_te\n",
    "\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 1\n",
    "    k_fold = 4\n",
    "    # lambdas = np.logspace(-10, 2, 30)\n",
    "    gammas = np.arange(0.0, 1.0, 0.1)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # *************************************************** \n",
    "    for gamma in gammas:\n",
    "        trainerrors = []\n",
    "        testerrors = []\n",
    "        for k in range(k_fold):\n",
    "            trainerror, testerror = cross_validation(y, tX, k_indices, k, gamma)\n",
    "            trainerrors.append(trainerror)\n",
    "            testerrors.append(testerror)\n",
    "        \n",
    "        mse_tr.append(np.mean(trainerrors))\n",
    "        mse_te.append(np.mean(testerrors))\n",
    "    \n",
    "    cross_validation_visualization(gammas, mse_tr, mse_te)\n",
    "\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide that a small gamma is ok, 0.5 seems good. We will just do one dummy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma = 0.5\n",
    "max_iters = 10\n",
    "loss, w = least_squares_GD(y, tX, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'pred_test1.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import api\n",
    "import helpers\n",
    "import evaluation\n",
    "import implementations\n",
    "import split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models comparison\n",
    "\n",
    "Let's compare 6 differents models to have a basic score allowing to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load train set\n",
    "\n",
    "# scaled between -1 (background) and 1 (Higgs)\n",
    "y, x, _ = helpers.load_csv_data('data/train.csv', sub_sample = True, background_value = -1)\n",
    "\n",
    "# scaled between 0 (background) and 1 (Higgs)\n",
    "# used in logistic regression\n",
    "y_rescaled, x_rescaled, _ = helpers.load_csv_data('data/train.csv', sub_sample = True, background_value = 0)\n",
    "x_rescaled,_ , _ = helpers.standardize(x_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.99000000e+02,   1.10000000e-02,   9.46300000e+00,\n",
       "         0.00000000e+00,  -9.99000000e+02,  -9.99000000e+02,\n",
       "        -9.99000000e+02,   2.56000000e-01,   0.00000000e+00,\n",
       "         4.62270000e+01,   1.36000000e-01,  -1.41400000e+00,\n",
       "        -9.99000000e+02,   2.00010000e+01,  -2.46800000e+00,\n",
       "        -3.14100000e+00,   2.60050000e+01,  -2.48200000e+00,\n",
       "        -3.14100000e+00,   5.37000000e-01,  -3.13900000e+00,\n",
       "         2.44160000e+01,   0.00000000e+00,  -9.99000000e+02,\n",
       "        -9.99000000e+02,  -9.99000000e+02,  -9.99000000e+02,\n",
       "        -9.99000000e+02,  -9.99000000e+02,   0.00000000e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Least Square\n",
      "te_loss = 0.8122\n",
      "accuracy = 0.6978\n",
      "-------------------------\n",
      "Least squares GD\n",
      "te_loss = 0.8292\n",
      "accuracy = 0.6894\n",
      "-------------------------\n",
      "Least squares SGD\n",
      "te_loss = 4.3905\n",
      "accuracy = 0.3286\n",
      "-------------------------\n",
      "Ridge Regression\n",
      "te_loss = 0.8181\n",
      "accuracy = 0.6966\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d78ca38c6c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# LR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mcross_validate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_rescaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_rescaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m,\u001b[0m                                                 \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# RLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d78ca38c6c92>\u001b[0m in \u001b[0;36mcross_validate_parameters\u001b[0;34m(y, x, function_name, method_name, cut, gammas, lambdas, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgammas\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m                            \u001b[0mmodel_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/api.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(y, x, poly, split_method, replace, cv, cut, model_func, lambdas, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inner_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/api.py\u001b[0m in \u001b[0;36m_inner_train\u001b[0;34m(y, x, poly, replace, cv, cut, model_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpoly\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joachimmuth/Documents/EPFL/PCML/PCML_project1/helpers.py\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(x, minX, rangeX)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mminX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mminX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrangeX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "\n",
    "def choose_best(cv, best):\n",
    "    if cv[2] < best[2]:\n",
    "        return cv\n",
    "    else:\n",
    "        return best\n",
    "    \n",
    "    \n",
    "def cross_validate_parameters(y, x, function_name, method_name,cut=0.5, gammas=None, lambdas=None, *args, **kwargs):\n",
    "    best = 0,0, float('inf'), 0\n",
    "    \n",
    "    if (lambdas is None) and (gammas is not None):\n",
    "        for i in gammas:\n",
    "            cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                           model_func=method_name, gamma = i, *args)\n",
    "            best = choose_best(cv, best)\n",
    "            \n",
    "    elif (gammas is None) and (lambdas is not None):\n",
    "        for i in lambdas:\n",
    "            cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                           model_func=method_name, lambda_ = i, *args)\n",
    "            best = choose_best(cv, best)\n",
    "            \n",
    "    elif (gammas is not None) and (lambdas is not None):\n",
    "        for i in gammas:\n",
    "            for j in lambdas:\n",
    "                cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                               model_func=method_name, gamma = i, lambda_ = j, *args)\n",
    "                best = choose_best(cv, best)\n",
    "                \n",
    "    else:\n",
    "        best = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                               model_func=method_name, *args)\n",
    "        \n",
    "    print(\"-------------------------\")\n",
    "    print(function_name)\n",
    "    print(\"te_loss = %.4f\" % best[2])\n",
    "    print(\"accuracy = %.4f\" % best[3])\n",
    "\n",
    "    return best\n",
    "\n",
    "# range parameter\n",
    "gammas = np.linspace(start=0.00001, stop=1, num=10)\n",
    "lambdas = np.logspace(start=-8, stop=0, num=10)\n",
    "max_iters = 10000\n",
    "\n",
    "\n",
    "# least squares\n",
    "cross_validate_parameters(y, x, 'Least Square', implementations.least_squares)\n",
    "\n",
    "# least squares GD\n",
    "cross_validate_parameters(y, x,'Least squares GD',  implementations.least_squares_GD, \\\n",
    "                                              gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# least squares Stochastic GD\n",
    "cross_validate_parameters(y, x,'Least squares SGD', implementations.least_squares_SGD, \\\n",
    "                                               gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# RR\n",
    "cross_validate_parameters(y, x, 'Ridge Regression', implementations.ridge_regression, lambdas = lambdas)\n",
    "\n",
    "\n",
    "# LR\n",
    "cross_validate_parameters(y_rescaled, x_rescaled,'Logistic Regression', implementations.logistic_regression, \\\n",
    "                                                cut = 0.5, gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# RLR\n",
    "cross_validate_parameters(y_rescaled, x_rescaled, 'Regularized Logistic Regression', \\\n",
    "                        implementations.reg_logistic_regression, cut = 0.5, gammas = gammas, \\\n",
    "                        lambdas = lambdas, max_iters = max_iters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test all the models\n",
    "\n",
    "# least square\n",
    "cv_least_squares = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=0., \\\n",
    "              model_func=implementations.least_squares)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Least squares: \")\n",
    "print(\"te_loss = %.4f\" % cv_least_squares[2])\n",
    "print(\"accuracy = %.4f\" % cv_least_squares[3])\n",
    "\n",
    "\n",
    "cv_least_squares_GD = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=0., \\\n",
    "              model_func=implementations.least_squares_GD, max_iters = 10000, gamma = 0.01)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Least squares GD: \")\n",
    "print(\"te_loss = %.4f\" % cv_least_squares_GD[2])\n",
    "print(\"accuracy = %.4f\" % cv_least_squares_GD[3])\n",
    "\n",
    "# least squares Stochastic GD\n",
    "cv_least_squares_SGD = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=0., \\\n",
    "              model_func=implementations.least_squares_SGD, max_iters = 10000, gamma = 0.1)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Least squares SGD: \")\n",
    "print(\"te_loss = %.4f\" % cv_least_squares_SGD[2])\n",
    "print(\"accuracy = %.4f\" % cv_least_squares_SGD[3])\n",
    "\n",
    "# RR\n",
    "cv_ridge_regression = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=0., \\\n",
    "              model_func=implementations.ridge_regression, lambda_ = 0.00000001)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Ridge Regression: \")\n",
    "print(\"te_loss = %.4f\" % cv_ridge_regression[2])\n",
    "print(\"accuracy = %.4f\" % cv_ridge_regression[3])\n",
    "\n",
    "# LR\n",
    "cv_logistic_regression = api.train(y_rescaled, x_rescaled, poly=0, split_method=None, replace=None, cv=True, cut=0.5, \\\n",
    "              model_func=implementations.logistic_regression, max_iters = 10000, gamma = 0.00001)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Logistic Regression: \")\n",
    "print(\"te_loss = %.4f\" % cv_logistic_regression[2])\n",
    "print(\"accuracy = %.4f\" % cv_logistic_regression[3])\n",
    "\n",
    "# Regularized LR\n",
    "cv_reg_logistic_regression = api.train(y_rescaled, x_rescaled, poly=0, split_method=None, replace=None, cv=True, cut=0.5, \\\n",
    "              model_func=implementations.reg_logistic_regression, lambda_ = 0.1, max_iters = 10000, gamma = 0.00001)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Logistic Regression: \")\n",
    "print(\"te_loss = %.4f\" % cv_reg_logistic_regression[2])\n",
    "print(\"accuracy = %.4f\" % cv_reg_logistic_regression[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.logspace(start=-8, stop=10, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test all the models\n",
    "gammas = np.linspace(start=0.000001, stop=1, num=10)\n",
    "lambdas = np.logspace(start=-8, stop=0, num=10)\n",
    "max_iters = 10000\n",
    "\n",
    "\n",
    "# least squares\n",
    "cross_validate_parameters(y, x, 'Least Square', implementations.least_squares)\n",
    "\n",
    "# least squares GD\n",
    "cross_validate_parameters(y, x,'Least squares GD',  implementations.least_squares_GD, \\\n",
    "                                                gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# least squares Stochastic GD\n",
    "cross_validate_parameters(y, x,'Least squares SGD', implementations.least_squares_SGD, \\\n",
    "                                                 gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# RR\n",
    "cross_validate_parameters(y, x, 'Ridge Regression', implementations.ridge_regression, lambdas = lambdas)\n",
    "\n",
    "\n",
    "# LR\n",
    "cross_validate_parameters(y_rescaled, x_rescaled,'Logistic Regression', implementations.logistic_regression, \\\n",
    "                                                  cut = 0.5, gammas = gammas, max_iters = max_iters)\n",
    "\n",
    "# RLR\n",
    "cross_validate_parameters(y_rescaled, x_rescaled, 'Regularized Logistic Regression', \\\n",
    "                          implementations.reg_logistic_regression, cut = 0.5, gammas = gammas, \\\n",
    "                          lambdas = lambdas, max_iters = max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import implementations\n",
    "# least squares GD\n",
    "\n",
    "def choose_best(cv, best):\n",
    "    if cv[2] < best[2]:\n",
    "        return cv\n",
    "    else:\n",
    "        return best\n",
    "    \n",
    "    \n",
    "def cross_validate_parameters(y, x, function_name, method_name,cut=0.5, gammas=None, lambdas=None, *args, **kwargs):\n",
    "    best = 0,0, float('inf'), 0\n",
    "    \n",
    "    if (lambdas is None) and (gammas is not None):\n",
    "        for i in gammas:\n",
    "            cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                           model_func=method_name, gamma = i, *args)\n",
    "            best = choose_best(cv, best)\n",
    "            \n",
    "    elif (gammas is None) and (lambdas is not None):\n",
    "        for i in lambdas:\n",
    "            cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                           model_func=method_name, lambda_ = i, *args)\n",
    "            best = choose_best(cv, best)\n",
    "            \n",
    "    elif (gammas is not None) and (lambdas is not None):\n",
    "        for i in gammas:\n",
    "            for j in lambdas:\n",
    "                cv = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                               model_func=method_name, gamma = i, lambda_ = j, *args)\n",
    "                best = choose_best(cv, best)\n",
    "                \n",
    "    else:\n",
    "        best = api.train(y, x, poly=0, split_method=None, replace=None, cv=True, cut=cut, \\\n",
    "                               model_func=method_name, *args)\n",
    "        \n",
    "    print(\"-------------------------\")\n",
    "    print(function_name)\n",
    "    print(\"te_loss = %.4f\" % best[2])\n",
    "    print(\"accuracy = %.4f\" % best[3])\n",
    "\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_validate_parameters(y, x, implementations.ridge_regression, lambdas = np.arange(0.0001, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

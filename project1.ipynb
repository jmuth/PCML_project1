{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from functions import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH, sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[ 1. -1. -1.  1.  1.  1. -1. -1.  1. -1.]\n",
      "[[  1.38470000e+02   5.16550000e+01   9.78270000e+01   2.79800000e+01\n",
      "    9.10000000e-01   1.24711000e+02   2.66600000e+00   3.06400000e+00\n",
      "    4.19280000e+01   1.97760000e+02   1.58200000e+00   1.39600000e+00\n",
      "    2.00000000e-01   3.26380000e+01   1.01700000e+00   3.81000000e-01\n",
      "    5.16260000e+01   2.27300000e+00  -2.41400000e+00   1.68240000e+01\n",
      "   -2.77000000e-01   2.58733000e+02   2.00000000e+00   6.74350000e+01\n",
      "    2.15000000e+00   4.44000000e-01   4.60620000e+01   1.24000000e+00\n",
      "   -2.47500000e+00   1.13497000e+02]\n",
      " [  2.19057000e+02   7.24610000e+01   1.24835000e+02   5.50600000e+00\n",
      "   -9.99000000e+02  -9.99000000e+02  -9.99000000e+02   3.77100000e+00\n",
      "    4.69360000e+01   1.22986000e+02   1.93200000e+00  -1.38200000e+00\n",
      "   -9.99000000e+02   2.47590000e+01  -1.06300000e+00   3.32000000e-01\n",
      "    4.78300000e+01   1.34700000e+00  -2.56900000e+00   2.84990000e+01\n",
      "    9.60000000e-01   9.03550000e+01   1.00000000e+00   5.03960000e+01\n",
      "   -7.08000000e-01  -6.42000000e-01  -9.99000000e+02  -9.99000000e+02\n",
      "   -9.99000000e+02   5.03960000e+01]]\n",
      "[100000 100050 100100 100150 100200 100250 100300 100350 100400 100450]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "head = range(10)\n",
    "print(y[head])\n",
    "print(tX[ range(2) ])\n",
    "print(ids[head])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a simple linear regression with least_square gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/9): loss=1.0, w0=57.80285279999999, w1=-14.487160399999999\n",
      "Gradient Descent(1/9): loss=1115219.0460117327, w0=-62710489.51710931, w1=25606519.608812366\n",
      "Gradient Descent(2/9): loss=3177000159991.1763, w0=168756041635166.22, w1=-72671335396127.05\n",
      "Gradient Descent(3/9): loss=9.052188135813353e+18, w0=-4.796405845402536e+20, w1=2.070394363938949e+20\n",
      "Gradient Descent(4/9): loss=2.579231201482503e+25, w0=1.366444326876951e+27, w1=-5.89913322506806e+26\n",
      "Gradient Descent(5/9): loss=7.3489785341655975e+31, w0=-3.8933581745766207e+33, w1=1.6808340549830848e+33\n",
      "Gradient Descent(6/9): loss=2.0939373510571364e+38, w0=1.1093299077739035e+40, w1=-4.7891841802214564e+39\n",
      "Gradient Descent(7/9): loss=5.966235456763936e+44, w0=-3.160802775852641e+46, w1=1.3645776187755787e+46\n",
      "Gradient Descent(8/9): loss=1.6999537024150425e+51, w0=9.006044749720856e+52, w1=-3.888077820493069e+52\n",
      "Gradient Descent(9/9): loss=4.843661654483296e+57, w0=-2.566083625081383e+59, w1=1.1078262556160841e+59\n"
     ]
    }
   ],
   "source": [
    "gamma = 1.0\n",
    "max_iter = 10\n",
    "loss, w = least_squares_SGD(y, tX, gamma, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[1.0, 1115219.0460117327, 3177000159991.1763, 9.0521881358133535e+18, 2.5792312014825031e+25, 7.3489785341655975e+31, 2.0939373510571364e+38, 5.9662354567639363e+44, 1.6999537024150425e+51, 4.8436616544832959e+57]\n"
     ]
    }
   ],
   "source": [
    "print(len(w))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some cross-validation, same as the HW4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import *\n",
    "from build_polynomial import build_poly\n",
    "\n",
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    # ***************************************************\n",
    "    ytest = y[k_indices[k]]\n",
    "    \n",
    "    not_k = np.array([i for i in range(len(x)) if i not in k_indices[k]])\n",
    "    ytrain = y[not_k]\n",
    "    xtest = x[k_indices[k]]\n",
    "    xtrain = x[not_k]\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form data with polynomial degree: TODO\n",
    "    # ***************************************************\n",
    "    txtrain = build_poly(xtrain, degree)\n",
    "    txtest = build_poly(xtest, degree)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    w = ridge_regression(ytrain, txtrain, lambda_)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate the loss for train and test data: TODO\n",
    "    # ***************************************************\n",
    "    loss_tr = compute_rmse(ytrain, txtrain, w)\n",
    "    loss_te = compute_rmse(ytest, txtest, w)\n",
    "    \n",
    "\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f07e875653d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcross_validation_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mcross_validation_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-f07e875653d1>\u001b[0m in \u001b[0;36mcross_validation_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtesterrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtrainerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesterror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtrainerrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtesterrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesterror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from plots import cross_validation_visualization\n",
    "from build_k_indices import *\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 1\n",
    "    degree = 7\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 2, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # *************************************************** \n",
    "    for lambda_ in lambdas:\n",
    "        trainerrors = []\n",
    "        testerrors = []\n",
    "        for k in range(k_fold):\n",
    "            trainerror, testerror = cross_validation(y, x, k_indices, k, lambda_, degree)\n",
    "            trainerrors.append(trainerror)\n",
    "            testerrors.append(testerror)\n",
    "        \n",
    "        mse_tr.append(np.mean(trainerrors))\n",
    "        mse_te.append(np.mean(testerrors))\n",
    "    \n",
    "    \n",
    "    cross_validation_visualization(lambdas, mse_tr, mse_te)\n",
    "\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
